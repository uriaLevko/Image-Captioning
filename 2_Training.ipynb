{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** \n",
    "decoder: runs resnet50, and outputs a connection layer with  dimention equels to the first input for the encoder (so, output the embedding size as parameter), no use of last softmax activation because we dont use classification so it removed.\n",
    "encoder: we start from the latent space vector that was outputed from the decoder as input for t=0. \n",
    "then we use the captions for the first t, and \"feed\" them to the first word embedding layer, we then concat them together to feed the lstm cell (we only have one layer of lstm). befor the first step we iniate the hidden first step only and set it to zero, we than use that layer for the first lstm step, who receives all thr cations one by one which followed by a linear layer to output the best fit word from the lstm as best fit for the next word (which is received from the training of course). \n",
    "batch = 200 is a good size when you have a strong gpu, vocab_threshold = 6 good size vocabulary - not to big, \n",
    "embed_size = 312 as the input, bigger maybe tends to overfit - after a few tries I got to this, \n",
    "hidden_size = 250, ones again, after a few tries that was good enough, num_epochs = 3 as  you suggested. \n",
    "\n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** \n",
    "I left it how it was. the transforms are good and fit the needs of the restnet architecture. with the addition of hflip, we get  some more variety to add complexity and  reduce the chance of overfitting.\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** \n",
    "we are using transferred learning for the decoder, which is able to detect patterns in a good way. allowing to train only the  embedding weights for the captions (lstm), we ensure we can focus on finding the right sequence of words, without having to train the heavy part of the cnn for days or even destroying the ability to generelize that the CNN have.\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:**\n",
    "for the loss,  CrossEntropyLoss is the obvies, but the paper recommend using another loss called \"doubly stochastic regularization\". this makes the model pay more attention to all the time steps. i might add this in the next stage.\n",
    "\n",
    "I chose Adam() as an optimizer with an initial learning rate of 0.001 - adam is updating the learning rate as we progress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> punkt\n",
      "    Downloading package punkt to /root/nltk_data...\n",
      "      Unzipping tokenizers/punkt.zip.\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n",
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 343/414113 [00:00<02:00, 3428.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 762/414113 [00:00<01:54, 3624.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1203/414113 [00:00<01:47, 3828.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1640/414113 [00:00<01:43, 3976.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2080/414113 [00:00<01:40, 4092.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2519/414113 [00:00<01:38, 4176.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2959/414113 [00:00<01:36, 4239.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3383/414113 [00:00<01:36, 4239.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3818/414113 [00:00<01:36, 4270.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4257/414113 [00:01<01:35, 4303.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4709/414113 [00:01<01:33, 4365.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5159/414113 [00:01<01:32, 4404.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 5601/414113 [00:01<01:32, 4408.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 6040/414113 [00:01<01:37, 4200.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 6468/414113 [00:01<01:36, 4222.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 6908/414113 [00:01<01:35, 4272.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7337/414113 [00:01<01:35, 4275.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 7765/414113 [00:01<01:36, 4219.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8220/414113 [00:01<01:34, 4312.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 8663/414113 [00:02<01:33, 4345.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9099/414113 [00:02<01:33, 4316.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9539/414113 [00:02<01:33, 4340.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9988/414113 [00:02<01:32, 4384.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10427/414113 [00:02<01:32, 4363.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 10864/414113 [00:02<01:33, 4316.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11303/414113 [00:02<01:32, 4337.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11737/414113 [00:02<01:33, 4313.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12171/414113 [00:02<01:33, 4320.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 12615/414113 [00:02<01:32, 4354.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13057/414113 [00:03<01:31, 4373.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13502/414113 [00:03<01:31, 4394.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 13942/414113 [00:03<01:31, 4350.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 14378/414113 [00:03<01:32, 4312.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 14832/414113 [00:03<01:31, 4375.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 15286/414113 [00:03<01:30, 4423.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 15729/414113 [00:03<01:31, 4359.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 16171/414113 [00:03<01:30, 4376.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 16624/414113 [00:03<01:29, 4418.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17067/414113 [00:03<01:30, 4402.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17510/414113 [00:04<01:29, 4409.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 17955/414113 [00:04<01:29, 4419.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 18398/414113 [00:04<01:29, 4413.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 18849/414113 [00:04<01:29, 4439.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 19298/414113 [00:04<01:28, 4453.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 19753/414113 [00:04<01:28, 4479.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 20202/414113 [00:04<01:28, 4428.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 20646/414113 [00:04<01:29, 4420.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 21089/414113 [00:04<01:28, 4419.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 21544/414113 [00:04<01:28, 4457.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 21990/414113 [00:05<01:28, 4451.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 22443/414113 [00:05<01:27, 4473.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 22891/414113 [00:05<01:27, 4471.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 23341/414113 [00:05<01:27, 4478.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 23789/414113 [00:05<01:29, 4371.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 24232/414113 [00:05<01:28, 4386.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 24672/414113 [00:05<01:28, 4380.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 25111/414113 [00:05<01:29, 4349.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 25563/414113 [00:05<01:28, 4399.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 26018/414113 [00:05<01:27, 4442.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 26463/414113 [00:06<01:27, 4434.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 26913/414113 [00:06<01:26, 4453.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 27359/414113 [00:06<01:27, 4404.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 27800/414113 [00:06<01:28, 4387.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 28239/414113 [00:06<01:27, 4386.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 28684/414113 [00:06<01:27, 4404.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 29125/414113 [00:06<01:28, 4344.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 29560/414113 [00:06<01:29, 4317.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 30020/414113 [00:06<01:27, 4392.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 30472/414113 [00:06<01:26, 4428.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 30916/414113 [00:07<01:26, 4413.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 31358/414113 [00:07<01:26, 4415.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 31800/414113 [00:07<01:26, 4398.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 32244/414113 [00:07<01:26, 4409.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 32686/414113 [00:07<01:28, 4302.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 33117/414113 [00:07<01:28, 4298.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 33555/414113 [00:07<01:28, 4321.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 34011/414113 [00:07<01:26, 4389.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 34451/414113 [00:07<01:27, 4346.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 34892/414113 [00:07<01:26, 4363.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 35337/414113 [00:08<01:26, 4387.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 35777/414113 [00:08<01:27, 4346.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 36223/414113 [00:08<01:26, 4377.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 36664/414113 [00:08<01:26, 4384.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 37118/414113 [00:08<01:25, 4427.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 37561/414113 [00:08<01:25, 4399.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 38008/414113 [00:08<01:25, 4418.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 38450/414113 [00:08<01:26, 4366.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 38890/414113 [00:08<01:25, 4375.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 39336/414113 [00:09<01:25, 4398.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 39782/414113 [00:09<01:24, 4413.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 40224/414113 [00:09<01:25, 4375.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 40662/414113 [00:09<01:25, 4367.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 41107/414113 [00:09<01:24, 4390.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 41556/414113 [00:09<01:24, 4419.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 41999/414113 [00:09<01:25, 4373.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 42439/414113 [00:09<01:24, 4379.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 42878/414113 [00:09<01:25, 4352.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 43314/414113 [00:09<01:25, 4338.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 43763/414113 [00:10<01:24, 4380.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 44206/414113 [00:10<01:24, 4394.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 44646/414113 [00:10<01:24, 4372.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 45087/414113 [00:10<01:24, 4380.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 45526/414113 [00:10<01:24, 4380.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 45967/414113 [00:10<01:23, 4385.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 46410/414113 [00:10<01:23, 4397.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 46850/414113 [00:10<01:24, 4357.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 47286/414113 [00:10<01:24, 4344.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 47729/414113 [00:10<01:23, 4368.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 48180/414113 [00:11<01:23, 4407.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 48638/414113 [00:11<01:22, 4456.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 49086/414113 [00:11<01:21, 4461.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 49540/414113 [00:11<01:21, 4483.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 49995/414113 [00:11<01:20, 4501.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 50446/414113 [00:11<01:21, 4481.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 50898/414113 [00:11<01:20, 4491.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 51348/414113 [00:11<01:21, 4442.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 51793/414113 [00:11<01:22, 4408.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 52236/414113 [00:11<01:21, 4414.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 52678/414113 [00:12<01:22, 4394.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 53118/414113 [00:12<01:22, 4388.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 53561/414113 [00:12<01:21, 4400.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 54004/414113 [00:12<01:21, 4409.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 54456/414113 [00:12<01:21, 4439.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 54901/414113 [00:12<01:21, 4421.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 55360/414113 [00:12<01:20, 4468.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 55811/414113 [00:12<01:19, 4479.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 56260/414113 [00:12<01:20, 4457.23it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 56706/414113 [00:13<02:24, 2476.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 57156/414113 [00:13<02:04, 2861.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 57612/414113 [00:13<01:50, 3221.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 58046/414113 [00:13<01:42, 3489.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 58486/414113 [00:13<01:35, 3718.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 58935/414113 [00:13<01:30, 3918.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 59390/414113 [00:13<01:26, 4088.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 59838/414113 [00:13<01:24, 4196.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 60292/414113 [00:14<01:22, 4291.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 60751/414113 [00:14<01:20, 4376.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 61200/414113 [00:14<01:20, 4366.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 61648/414113 [00:14<01:20, 4397.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 62093/414113 [00:14<01:20, 4398.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 62543/414113 [00:14<01:19, 4427.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 62997/414113 [00:14<01:18, 4459.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 63445/414113 [00:14<01:18, 4465.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 63895/414113 [00:14<01:18, 4473.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 64344/414113 [00:14<01:19, 4420.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 64787/414113 [00:15<01:19, 4392.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 65228/414113 [00:15<01:19, 4395.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 65669/414113 [00:15<01:19, 4384.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 66108/414113 [00:15<01:19, 4377.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 66546/414113 [00:15<01:20, 4333.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 66985/414113 [00:15<01:19, 4348.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 67431/414113 [00:15<01:19, 4379.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 67876/414113 [00:15<01:18, 4397.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 68328/414113 [00:15<01:18, 4432.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 68776/414113 [00:15<01:17, 4443.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 69221/414113 [00:16<01:18, 4386.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 69660/414113 [00:16<01:19, 4351.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 70120/414113 [00:16<01:17, 4420.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 70568/414113 [00:16<01:17, 4436.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 71012/414113 [00:16<01:17, 4402.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 71465/414113 [00:16<01:17, 4439.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 71923/414113 [00:16<01:16, 4480.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 72372/414113 [00:16<01:17, 4412.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 72814/414113 [00:16<01:18, 4348.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 73250/414113 [00:16<01:19, 4311.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 73704/414113 [00:17<01:17, 4377.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 74143/414113 [00:17<01:18, 4346.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 74597/414113 [00:17<01:17, 4400.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 75039/414113 [00:17<01:16, 4404.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 75484/414113 [00:17<01:16, 4416.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 75926/414113 [00:17<01:17, 4381.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 76375/414113 [00:17<01:16, 4411.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 76824/414113 [00:17<01:16, 4433.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 77268/414113 [00:17<01:17, 4370.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 77716/414113 [00:17<01:16, 4401.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 78159/414113 [00:18<01:16, 4409.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 78602/414113 [00:18<01:16, 4413.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 79052/414113 [00:18<01:15, 4436.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 79496/414113 [00:18<01:15, 4419.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 79939/414113 [00:18<01:15, 4414.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 80381/414113 [00:18<01:18, 4228.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 80826/414113 [00:18<01:17, 4290.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 81268/414113 [00:18<01:16, 4325.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 81705/414113 [00:18<01:16, 4338.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 82147/414113 [00:18<01:16, 4359.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 82603/414113 [00:19<01:15, 4416.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 83048/414113 [00:19<01:14, 4424.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 83491/414113 [00:19<01:14, 4409.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 83937/414113 [00:19<01:14, 4424.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 84394/414113 [00:19<01:13, 4465.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 84848/414113 [00:19<01:13, 4484.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 85310/414113 [00:19<01:12, 4522.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 85763/414113 [00:19<01:12, 4517.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 86215/414113 [00:19<01:12, 4515.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 86667/414113 [00:19<01:13, 4450.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 87116/414113 [00:20<01:13, 4460.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 87563/414113 [00:20<01:13, 4457.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 88013/414113 [00:20<01:12, 4469.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 88475/414113 [00:20<01:12, 4512.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 88927/414113 [00:20<01:12, 4499.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 89385/414113 [00:20<01:11, 4520.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 89838/414113 [00:20<01:12, 4481.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 90296/414113 [00:20<01:11, 4510.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 90755/414113 [00:20<01:11, 4531.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 91209/414113 [00:20<01:11, 4527.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 91662/414113 [00:21<01:11, 4522.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 92115/414113 [00:21<01:15, 4238.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 92554/414113 [00:21<01:15, 4279.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 93000/414113 [00:21<01:14, 4330.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 93460/414113 [00:21<01:12, 4407.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 93919/414113 [00:21<01:11, 4459.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 94367/414113 [00:21<01:11, 4452.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 94820/414113 [00:21<01:11, 4474.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 95269/414113 [00:21<01:11, 4474.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 95717/414113 [00:22<01:12, 4421.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 96160/414113 [00:22<01:12, 4404.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 96627/414113 [00:22<01:10, 4479.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 97076/414113 [00:22<01:11, 4437.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 97525/414113 [00:22<01:11, 4450.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 97990/414113 [00:22<01:10, 4508.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 98443/414113 [00:22<01:09, 4514.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 98895/414113 [00:22<01:10, 4470.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 99344/414113 [00:22<01:10, 4474.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 99795/414113 [00:22<01:10, 4484.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 100244/414113 [00:23<01:10, 4457.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 100690/414113 [00:23<01:10, 4421.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 101136/414113 [00:23<01:10, 4432.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 101580/414113 [00:23<01:11, 4362.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 102017/414113 [00:23<01:11, 4360.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 102454/414113 [00:23<01:11, 4359.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 102918/414113 [00:23<01:10, 4439.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 103370/414113 [00:23<01:09, 4462.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 103817/414113 [00:23<01:10, 4418.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 104269/414113 [00:23<01:09, 4447.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 104714/414113 [00:24<01:10, 4418.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 105157/414113 [00:24<01:10, 4389.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 105602/414113 [00:24<01:10, 4406.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 106043/414113 [00:24<01:10, 4376.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 106490/414113 [00:24<01:09, 4401.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 106931/414113 [00:24<01:11, 4312.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 107376/414113 [00:24<01:10, 4349.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 107812/414113 [00:24<01:11, 4313.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 108265/414113 [00:24<01:09, 4375.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 108713/414113 [00:24<01:09, 4404.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 109154/414113 [00:25<01:09, 4389.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 109594/414113 [00:25<01:09, 4376.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 110032/414113 [00:25<01:09, 4371.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 110474/414113 [00:25<01:09, 4383.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 110914/414113 [00:25<01:09, 4387.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 111360/414113 [00:25<01:08, 4407.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 111821/414113 [00:25<01:07, 4463.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 112268/414113 [00:25<01:07, 4454.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 112716/414113 [00:25<01:07, 4459.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 113173/414113 [00:25<01:06, 4492.09it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 113623/414113 [00:26<01:07, 4427.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 114085/414113 [00:26<01:06, 4481.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 114534/414113 [00:26<01:07, 4423.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 114986/414113 [00:26<01:07, 4449.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 115443/414113 [00:26<01:06, 4484.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 115892/414113 [00:26<01:06, 4463.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 116339/414113 [00:26<01:06, 4458.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 116786/414113 [00:26<01:07, 4421.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 117229/414113 [00:26<01:07, 4415.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 117689/414113 [00:26<01:06, 4467.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 118137/414113 [00:27<01:06, 4457.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 118583/414113 [00:27<01:06, 4449.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 119029/414113 [00:27<01:06, 4442.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 119474/414113 [00:27<01:06, 4425.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 119933/414113 [00:27<01:05, 4472.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 120388/414113 [00:27<01:05, 4495.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 120838/414113 [00:27<01:05, 4483.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 121287/414113 [00:27<01:05, 4470.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 121735/414113 [00:27<01:05, 4447.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 122191/414113 [00:27<01:05, 4480.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 122640/414113 [00:28<01:05, 4450.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 123086/414113 [00:28<01:05, 4436.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 123533/414113 [00:28<01:05, 4443.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 123984/414113 [00:28<01:05, 4461.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 124452/414113 [00:28<01:04, 4522.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 124918/414113 [00:28<01:03, 4559.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 125376/414113 [00:28<01:03, 4564.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 125833/414113 [00:28<01:03, 4538.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 126287/414113 [00:28<01:03, 4526.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 126740/414113 [00:29<01:05, 4396.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 127200/414113 [00:29<01:04, 4453.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 127647/414113 [00:29<01:04, 4452.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 128094/414113 [00:29<01:04, 4455.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 128540/414113 [00:29<01:04, 4444.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 128993/414113 [00:29<01:03, 4466.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 129452/414113 [00:29<01:03, 4502.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 129903/414113 [00:29<01:03, 4487.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 130352/414113 [00:29<01:03, 4487.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 130801/414113 [00:29<01:03, 4438.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 131246/414113 [00:30<01:04, 4415.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 131699/414113 [00:30<01:03, 4447.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 132144/414113 [00:30<01:03, 4417.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 132597/414113 [00:30<01:03, 4450.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 133043/414113 [00:30<01:03, 4427.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 133486/414113 [00:30<01:03, 4410.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 133928/414113 [00:30<01:04, 4377.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 134379/414113 [00:30<01:03, 4414.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 134821/414113 [00:30<01:03, 4394.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 135281/414113 [00:30<01:02, 4454.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 135731/414113 [00:31<01:02, 4465.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 136178/414113 [00:31<01:02, 4435.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 136631/414113 [00:31<01:02, 4462.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 137078/414113 [00:31<01:02, 4430.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 137529/414113 [00:31<01:02, 4453.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 137975/414113 [00:31<01:02, 4418.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 138426/414113 [00:31<01:02, 4444.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 138872/414113 [00:31<01:01, 4447.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 139317/414113 [00:31<01:02, 4411.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 139767/414113 [00:31<01:01, 4436.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 140211/414113 [00:32<01:02, 4377.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 140654/414113 [00:32<01:02, 4390.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 141094/414113 [00:32<01:02, 4367.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 141542/414113 [00:32<01:01, 4399.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 141983/414113 [00:32<01:05, 4127.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 142439/414113 [00:32<01:04, 4244.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 142880/414113 [00:32<01:03, 4290.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 143325/414113 [00:32<01:02, 4337.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 143768/414113 [00:32<01:01, 4364.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 144211/414113 [00:32<01:01, 4382.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 144651/414113 [00:33<01:01, 4375.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 145090/414113 [00:33<01:01, 4378.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 145546/414113 [00:33<01:00, 4429.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 145990/414113 [00:33<01:00, 4422.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 146433/414113 [00:33<01:00, 4424.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 146879/414113 [00:33<01:00, 4433.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 147327/414113 [00:33<01:00, 4445.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 147772/414113 [00:33<01:00, 4409.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 148214/414113 [00:33<01:00, 4391.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 148660/414113 [00:33<01:00, 4410.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 149102/414113 [00:34<01:00, 4396.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 149542/414113 [00:34<01:00, 4389.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 149988/414113 [00:34<00:59, 4408.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 150429/414113 [00:34<01:01, 4321.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 150885/414113 [00:34<00:59, 4389.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 151342/414113 [00:34<00:59, 4441.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 151797/414113 [00:34<00:58, 4472.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 152245/414113 [00:34<00:58, 4462.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 152692/414113 [00:34<00:58, 4440.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 153142/414113 [00:34<00:58, 4456.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 153592/414113 [00:35<00:58, 4468.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 154056/414113 [00:35<00:57, 4517.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 154510/414113 [00:35<00:57, 4522.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 154963/414113 [00:35<00:57, 4484.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 155418/414113 [00:35<00:57, 4502.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 155870/414113 [00:35<00:57, 4506.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 156321/414113 [00:35<00:57, 4465.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 156768/414113 [00:35<00:58, 4427.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 157220/414113 [00:35<00:57, 4454.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 157675/414113 [00:35<00:57, 4480.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 158131/414113 [00:36<00:56, 4503.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 158582/414113 [00:36<00:56, 4498.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 159043/414113 [00:36<00:56, 4529.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 159497/414113 [00:36<00:56, 4481.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 159957/414113 [00:36<00:56, 4514.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 160409/414113 [00:36<00:56, 4505.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 160860/414113 [00:36<00:56, 4497.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 161311/414113 [00:36<00:56, 4501.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 161767/414113 [00:36<00:55, 4517.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 162225/414113 [00:37<00:55, 4535.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 162685/414113 [00:37<00:55, 4553.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 163154/414113 [00:37<00:54, 4593.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 163614/414113 [00:37<00:54, 4591.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 164074/414113 [00:37<00:54, 4553.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 164530/414113 [00:37<00:55, 4526.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 164983/414113 [00:37<00:55, 4480.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 165432/414113 [00:37<00:55, 4467.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 165879/414113 [00:37<00:55, 4444.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 166324/414113 [00:37<00:56, 4387.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 166764/414113 [00:38<00:57, 4330.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 167198/414113 [00:38<00:57, 4315.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 167650/414113 [00:38<00:56, 4373.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 168102/414113 [00:38<00:55, 4415.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 168556/414113 [00:38<00:55, 4451.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 169002/414113 [00:38<00:55, 4420.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 169445/414113 [00:38<00:55, 4382.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 169893/414113 [00:38<00:55, 4408.99it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 170335/414113 [00:38<00:56, 4306.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 170769/414113 [00:38<00:56, 4316.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 171218/414113 [00:39<00:55, 4365.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 171659/414113 [00:39<00:55, 4377.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 172104/414113 [00:39<00:55, 4397.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 172553/414113 [00:39<00:54, 4422.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 172996/414113 [00:39<00:55, 4350.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 173436/414113 [00:39<00:55, 4365.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 173873/414113 [00:39<01:44, 2307.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 174302/414113 [00:40<01:29, 2677.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 174750/414113 [00:40<01:18, 3044.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 175179/414113 [00:40<01:11, 3333.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 175608/414113 [00:40<01:06, 3570.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 176018/414113 [00:40<01:04, 3706.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 176460/414113 [00:40<01:01, 3893.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 176921/414113 [00:40<00:58, 4081.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 177352/414113 [00:40<00:57, 4143.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 177801/414113 [00:40<00:55, 4240.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 178237/414113 [00:40<00:55, 4218.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 178680/414113 [00:41<00:55, 4278.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 179114/414113 [00:41<00:54, 4292.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 179561/414113 [00:41<00:54, 4342.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 179999/414113 [00:41<00:53, 4353.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 180448/414113 [00:41<00:53, 4393.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 180889/414113 [00:41<00:53, 4369.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 181334/414113 [00:41<00:52, 4392.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 181786/414113 [00:41<00:52, 4427.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 182235/414113 [00:41<00:52, 4446.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 182681/414113 [00:41<00:52, 4415.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 183123/414113 [00:42<00:52, 4401.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 183564/414113 [00:42<00:53, 4346.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 184004/414113 [00:42<00:52, 4360.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 184447/414113 [00:42<00:52, 4378.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 184895/414113 [00:42<00:52, 4406.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 185356/414113 [00:42<00:51, 4464.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 185805/414113 [00:42<00:51, 4470.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 186255/414113 [00:42<00:50, 4478.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 186703/414113 [00:42<00:51, 4409.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 187158/414113 [00:42<00:50, 4451.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 187604/414113 [00:43<00:50, 4446.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 188049/414113 [00:43<00:51, 4412.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 188491/414113 [00:43<00:51, 4414.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 188940/414113 [00:43<00:50, 4435.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 189384/414113 [00:43<00:50, 4418.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 189826/414113 [00:43<00:50, 4409.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 190274/414113 [00:43<00:50, 4428.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 190731/414113 [00:43<00:49, 4469.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 191182/414113 [00:43<00:49, 4480.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 191634/414113 [00:43<00:49, 4489.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 192084/414113 [00:44<00:49, 4483.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 192547/414113 [00:44<00:48, 4524.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 193000/414113 [00:44<00:49, 4476.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 193448/414113 [00:44<00:49, 4475.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 193897/414113 [00:44<00:49, 4477.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 194345/414113 [00:44<00:49, 4431.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 194789/414113 [00:44<00:50, 4316.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 195224/414113 [00:44<00:50, 4325.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 195667/414113 [00:44<00:50, 4355.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 196117/414113 [00:44<00:49, 4395.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 196557/414113 [00:45<00:49, 4375.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 197010/414113 [00:45<00:49, 4420.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 197453/414113 [00:45<00:49, 4416.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 197909/414113 [00:45<00:48, 4458.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 198363/414113 [00:45<00:48, 4481.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 198812/414113 [00:45<00:48, 4466.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 199259/414113 [00:45<00:48, 4439.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 199704/414113 [00:45<00:48, 4396.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 200144/414113 [00:45<00:48, 4389.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 200593/414113 [00:46<00:48, 4417.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 201053/414113 [00:46<00:47, 4468.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 201519/414113 [00:46<00:47, 4522.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 201972/414113 [00:46<00:47, 4483.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 202422/414113 [00:46<00:47, 4484.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 202880/414113 [00:46<00:46, 4510.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 203340/414113 [00:46<00:46, 4536.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 203794/414113 [00:46<00:47, 4435.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 204239/414113 [00:46<00:47, 4396.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 204693/414113 [00:46<00:47, 4436.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 205149/414113 [00:47<00:46, 4472.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 205597/414113 [00:47<00:47, 4415.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 206055/414113 [00:47<00:46, 4463.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 206502/414113 [00:47<00:46, 4453.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 206948/414113 [00:47<00:46, 4430.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 207393/414113 [00:47<00:46, 4434.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 207837/414113 [00:47<00:47, 4385.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 208276/414113 [00:47<00:47, 4377.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 208715/414113 [00:47<00:46, 4379.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 209183/414113 [00:47<00:45, 4462.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 209632/414113 [00:48<00:45, 4470.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 210091/414113 [00:48<00:45, 4505.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 210544/414113 [00:48<00:45, 4512.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 210996/414113 [00:48<00:45, 4505.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 211450/414113 [00:48<00:44, 4515.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 211902/414113 [00:48<00:45, 4490.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 212365/414113 [00:48<00:44, 4530.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 212822/414113 [00:48<00:44, 4539.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 213277/414113 [00:48<00:44, 4495.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 213739/414113 [00:48<00:44, 4530.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 214193/414113 [00:49<00:44, 4496.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 214643/414113 [00:49<00:44, 4495.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 215093/414113 [00:49<00:44, 4428.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 215537/414113 [00:49<00:45, 4398.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 215978/414113 [00:49<00:45, 4388.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 216418/414113 [00:49<00:45, 4358.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 216855/414113 [00:49<00:45, 4347.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 217305/414113 [00:49<00:44, 4391.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 217754/414113 [00:49<00:44, 4418.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 218224/414113 [00:49<00:43, 4498.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 218681/414113 [00:50<00:43, 4517.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 219148/414113 [00:50<00:42, 4560.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 219605/414113 [00:50<00:43, 4512.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 220063/414113 [00:50<00:42, 4532.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 220518/414113 [00:50<00:42, 4536.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 220972/414113 [00:50<00:43, 4487.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 221421/414113 [00:50<00:43, 4453.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 221888/414113 [00:50<00:42, 4515.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 222340/414113 [00:50<00:42, 4492.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 222790/414113 [00:50<00:43, 4427.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 223257/414113 [00:51<00:42, 4495.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 223710/414113 [00:51<00:42, 4503.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 224174/414113 [00:51<00:41, 4539.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 224634/414113 [00:51<00:41, 4555.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 225097/414113 [00:51<00:41, 4576.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 225555/414113 [00:51<00:41, 4518.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 226016/414113 [00:51<00:41, 4545.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 226472/414113 [00:51<00:41, 4549.04it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 226946/414113 [00:51<00:40, 4602.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 227407/414113 [00:51<00:41, 4497.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 227870/414113 [00:52<00:41, 4536.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 228325/414113 [00:52<00:41, 4523.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 228778/414113 [00:52<00:41, 4498.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 229229/414113 [00:52<00:41, 4439.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 229674/414113 [00:52<00:42, 4338.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 230117/414113 [00:52<00:42, 4363.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 230554/414113 [00:52<00:42, 4327.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 230992/414113 [00:52<00:42, 4341.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 231437/414113 [00:52<00:41, 4373.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 231892/414113 [00:53<00:41, 4423.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 232335/414113 [00:53<00:41, 4375.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 232773/414113 [00:53<00:41, 4372.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 233229/414113 [00:53<00:40, 4425.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 233689/414113 [00:53<00:40, 4474.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 234137/414113 [00:53<00:40, 4459.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 234584/414113 [00:53<00:40, 4461.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 235031/414113 [00:53<00:40, 4436.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 235475/414113 [00:53<00:40, 4436.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 235938/414113 [00:53<00:39, 4490.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 236388/414113 [00:54<00:39, 4476.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 236836/414113 [00:54<00:39, 4464.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 237283/414113 [00:54<00:40, 4366.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 237731/414113 [00:54<00:40, 4398.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 238180/414113 [00:54<00:39, 4423.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 238626/414113 [00:54<00:39, 4432.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 239070/414113 [00:54<00:39, 4405.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 239528/414113 [00:54<00:39, 4454.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 239974/414113 [00:54<00:39, 4372.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 240424/414113 [00:54<00:39, 4408.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 240866/414113 [00:55<00:39, 4392.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 241306/414113 [00:55<00:39, 4390.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 241746/414113 [00:55<00:39, 4360.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 242192/414113 [00:55<00:39, 4388.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 242632/414113 [00:55<00:39, 4386.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 243077/414113 [00:55<00:38, 4402.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 243534/414113 [00:55<00:38, 4449.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 243984/414113 [00:55<00:38, 4461.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 244442/414113 [00:55<00:37, 4494.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 244905/414113 [00:55<00:37, 4533.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 245363/414113 [00:56<00:37, 4546.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 245818/414113 [00:56<00:37, 4535.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 246272/414113 [00:56<00:37, 4496.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 246722/414113 [00:56<00:37, 4450.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 247183/414113 [00:56<00:37, 4496.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 247633/414113 [00:56<00:37, 4460.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 248091/414113 [00:56<00:36, 4494.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 248541/414113 [00:56<00:37, 4459.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 249000/414113 [00:56<00:36, 4497.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 249453/414113 [00:56<00:36, 4505.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 249904/414113 [00:57<00:36, 4502.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 250355/414113 [00:57<00:36, 4490.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 250805/414113 [00:57<00:36, 4474.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 251253/414113 [00:57<00:36, 4436.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 251706/414113 [00:57<00:36, 4463.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 252155/414113 [00:57<00:36, 4470.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 252612/414113 [00:57<00:35, 4497.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 253062/414113 [00:57<00:36, 4449.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 253508/414113 [00:57<00:36, 4442.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 253953/414113 [00:57<00:36, 4436.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 254399/414113 [00:58<00:35, 4440.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 254845/414113 [00:58<00:35, 4445.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 255302/414113 [00:58<00:35, 4480.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 255751/414113 [00:58<00:36, 4330.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 256204/414113 [00:58<00:35, 4388.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 256664/414113 [00:58<00:35, 4449.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 257110/414113 [00:58<00:35, 4451.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 257568/414113 [00:58<00:34, 4486.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 258018/414113 [00:58<00:34, 4488.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 258470/414113 [00:58<00:34, 4495.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 258920/414113 [00:59<00:34, 4451.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 259366/414113 [00:59<00:34, 4447.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 259823/414113 [00:59<00:34, 4482.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 260285/414113 [00:59<00:34, 4521.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 260738/414113 [00:59<00:34, 4492.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 261188/414113 [00:59<00:34, 4484.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 261637/414113 [00:59<00:34, 4483.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 262086/414113 [00:59<00:34, 4453.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 262532/414113 [00:59<00:34, 4389.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 262990/414113 [00:59<00:34, 4442.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 263435/414113 [01:00<00:34, 4407.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 263877/414113 [01:00<00:34, 4357.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 264321/414113 [01:00<00:34, 4381.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 264765/414113 [01:00<00:33, 4396.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 265205/414113 [01:00<00:33, 4383.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 265644/414113 [01:00<00:33, 4380.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 266086/414113 [01:00<00:33, 4390.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 266528/414113 [01:00<00:33, 4398.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 266969/414113 [01:00<00:33, 4398.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 267409/414113 [01:00<00:33, 4385.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 267859/414113 [01:01<00:33, 4418.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 268301/414113 [01:01<00:33, 4408.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 268742/414113 [01:01<00:33, 4396.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 269182/414113 [01:01<00:33, 4354.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 269633/414113 [01:01<00:32, 4399.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 270086/414113 [01:01<00:32, 4437.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 270530/414113 [01:01<00:32, 4425.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 270973/414113 [01:01<00:32, 4384.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 271420/414113 [01:01<00:32, 4408.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 271870/414113 [01:02<00:32, 4433.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 272316/414113 [01:02<00:31, 4439.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 272761/414113 [01:02<00:32, 4412.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 273203/414113 [01:02<00:32, 4395.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 273643/414113 [01:02<00:32, 4350.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 274088/414113 [01:02<00:31, 4377.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 274542/414113 [01:02<00:31, 4425.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 274991/414113 [01:02<00:31, 4443.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 275440/414113 [01:02<00:31, 4455.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 275886/414113 [01:02<00:31, 4416.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 276342/414113 [01:03<00:30, 4458.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 276789/414113 [01:03<00:30, 4461.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 277237/414113 [01:03<00:30, 4466.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 277692/414113 [01:03<00:30, 4489.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 278142/414113 [01:03<00:30, 4453.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 278588/414113 [01:03<00:30, 4447.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 279040/414113 [01:03<00:30, 4467.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 279487/414113 [01:03<00:30, 4442.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 279941/414113 [01:03<00:30, 4469.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 280389/414113 [01:03<00:29, 4458.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 280835/414113 [01:04<00:29, 4458.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 281281/414113 [01:04<00:30, 4399.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 281733/414113 [01:04<00:29, 4433.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 282181/414113 [01:04<00:29, 4445.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 282632/414113 [01:04<00:29, 4462.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 283091/414113 [01:04<00:29, 4497.91it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 283551/414113 [01:04<00:28, 4526.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 284004/414113 [01:04<00:29, 4435.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 284456/414113 [01:04<00:29, 4460.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 284912/414113 [01:04<00:28, 4487.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 285362/414113 [01:05<00:28, 4449.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 285813/414113 [01:05<00:28, 4466.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 286260/414113 [01:05<00:28, 4457.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 286710/414113 [01:05<00:28, 4469.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 287158/414113 [01:05<00:28, 4454.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 287609/414113 [01:05<00:28, 4468.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 288068/414113 [01:05<00:27, 4504.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 288519/414113 [01:05<00:27, 4490.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 288969/414113 [01:05<00:27, 4474.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 289417/414113 [01:05<00:27, 4473.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 289888/414113 [01:06<00:27, 4539.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 290343/414113 [01:06<00:27, 4477.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 290795/414113 [01:06<00:27, 4487.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 291245/414113 [01:06<00:27, 4469.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 291699/414113 [01:06<00:27, 4487.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 292157/414113 [01:06<00:27, 4514.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 292619/414113 [01:06<00:26, 4543.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 293074/414113 [01:06<00:26, 4542.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 293538/414113 [01:06<00:26, 4569.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 293996/414113 [01:06<00:26, 4528.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 294449/414113 [01:07<00:26, 4485.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 294900/414113 [01:07<00:26, 4490.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 295351/414113 [01:07<00:26, 4495.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 295801/414113 [01:07<00:26, 4480.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 296255/414113 [01:07<00:26, 4496.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 296705/414113 [01:07<00:26, 4491.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 297163/414113 [01:07<00:25, 4515.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 297615/414113 [01:07<00:25, 4483.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 298064/414113 [01:07<00:26, 4459.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 298511/414113 [01:07<00:25, 4446.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 298957/414113 [01:08<00:25, 4450.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 299403/414113 [01:08<00:25, 4430.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 299863/414113 [01:08<00:25, 4479.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 300312/414113 [01:08<00:25, 4460.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 300770/414113 [01:08<00:25, 4494.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 301220/414113 [01:08<00:25, 4490.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 301670/414113 [01:08<00:25, 4440.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 302124/414113 [01:08<00:25, 4466.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 302571/414113 [01:08<00:25, 4452.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 303019/414113 [01:08<00:24, 4459.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 303482/414113 [01:09<00:24, 4506.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 303933/414113 [01:09<00:24, 4454.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 304379/414113 [01:09<00:24, 4450.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 304825/414113 [01:09<00:24, 4418.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 305282/414113 [01:09<00:24, 4460.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 305729/414113 [01:09<00:24, 4452.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 306175/414113 [01:09<00:24, 4441.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 306623/414113 [01:09<00:24, 4452.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 307069/414113 [01:09<00:24, 4395.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 307512/414113 [01:09<00:24, 4403.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 307953/414113 [01:10<00:24, 4387.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 308399/414113 [01:10<00:23, 4408.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 308843/414113 [01:10<00:23, 4415.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 309300/414113 [01:10<00:23, 4459.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 309747/414113 [01:10<00:23, 4460.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 310194/414113 [01:10<00:23, 4451.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 310640/414113 [01:10<00:23, 4423.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 311090/414113 [01:10<00:23, 4446.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 311535/414113 [01:10<00:23, 4420.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 311978/414113 [01:10<00:23, 4411.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 312420/414113 [01:11<00:23, 4408.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 312877/414113 [01:11<00:22, 4455.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 313323/414113 [01:11<00:22, 4440.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 313768/414113 [01:11<00:24, 4062.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 314227/414113 [01:11<00:23, 4205.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 314686/414113 [01:11<00:23, 4313.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 315132/414113 [01:11<00:22, 4356.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 315578/414113 [01:11<00:22, 4385.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 316027/414113 [01:11<00:22, 4414.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 316471/414113 [01:12<00:22, 4402.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 316927/414113 [01:12<00:21, 4447.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 317386/414113 [01:12<00:21, 4486.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 317836/414113 [01:12<00:21, 4438.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 318281/414113 [01:12<00:21, 4402.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 318735/414113 [01:12<00:21, 4441.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 319186/414113 [01:12<00:21, 4461.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 319633/414113 [01:12<00:21, 4445.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 320093/414113 [01:12<00:20, 4488.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 320543/414113 [01:12<00:20, 4486.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 320996/414113 [01:13<00:20, 4498.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 321447/414113 [01:13<00:20, 4475.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 321895/414113 [01:13<00:20, 4446.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 322340/414113 [01:13<00:20, 4431.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 322790/414113 [01:13<00:20, 4451.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 323236/414113 [01:13<00:20, 4332.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 323671/414113 [01:13<00:20, 4333.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 324111/414113 [01:13<00:20, 4353.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 324547/414113 [01:14<00:42, 2117.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 325001/414113 [01:14<00:35, 2520.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 325457/414113 [01:14<00:30, 2910.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 325915/414113 [01:14<00:27, 3266.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 326383/414113 [01:14<00:24, 3591.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 326834/414113 [01:14<00:22, 3824.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 327283/414113 [01:14<00:21, 4000.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 327731/414113 [01:14<00:20, 4131.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 328174/414113 [01:15<00:20, 4174.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 328613/414113 [01:15<00:20, 4235.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 329052/414113 [01:15<00:19, 4253.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 329492/414113 [01:15<00:19, 4293.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 329936/414113 [01:15<00:19, 4334.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 330382/414113 [01:15<00:19, 4369.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 330823/414113 [01:15<00:19, 4355.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 331262/414113 [01:15<00:19, 4308.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 331719/414113 [01:15<00:18, 4382.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 332170/414113 [01:15<00:18, 4419.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 332614/414113 [01:16<00:18, 4351.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 333051/414113 [01:16<00:18, 4334.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 333517/414113 [01:16<00:18, 4424.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 333961/414113 [01:16<00:18, 4421.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 334404/414113 [01:16<00:18, 4396.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 334845/414113 [01:16<00:18, 4391.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 335290/414113 [01:16<00:17, 4406.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 335731/414113 [01:16<00:18, 4313.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 336164/414113 [01:16<00:18, 4318.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 336612/414113 [01:16<00:17, 4364.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 337049/414113 [01:17<00:17, 4310.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 337497/414113 [01:17<00:17, 4357.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 337934/414113 [01:17<00:18, 4189.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 338368/414113 [01:17<00:17, 4231.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 338814/414113 [01:17<00:17, 4295.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 339245/414113 [01:17<00:17, 4278.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 339674/414113 [01:17<00:17, 4280.19it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 340122/414113 [01:17<00:17, 4338.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 340558/414113 [01:17<00:16, 4344.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 340998/414113 [01:17<00:16, 4360.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 341435/414113 [01:18<00:16, 4353.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 341882/414113 [01:18<00:16, 4385.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 342327/414113 [01:18<00:16, 4403.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 342768/414113 [01:18<00:16, 4380.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 343212/414113 [01:18<00:16, 4398.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 343656/414113 [01:18<00:15, 4410.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 344109/414113 [01:18<00:15, 4443.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 344560/414113 [01:18<00:15, 4461.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 345011/414113 [01:18<00:15, 4475.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 345459/414113 [01:18<00:15, 4475.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 345907/414113 [01:19<00:15, 4466.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 346364/414113 [01:19<00:15, 4496.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 346814/414113 [01:19<00:14, 4489.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 347264/414113 [01:19<00:14, 4491.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 347714/414113 [01:19<00:14, 4460.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 348161/414113 [01:19<00:14, 4447.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 348608/414113 [01:19<00:14, 4452.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 349054/414113 [01:19<00:14, 4400.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 349495/414113 [01:19<00:14, 4359.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 349932/414113 [01:19<00:14, 4344.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 350395/414113 [01:20<00:14, 4423.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 350854/414113 [01:20<00:14, 4471.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 351310/414113 [01:20<00:13, 4494.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 351760/414113 [01:20<00:13, 4475.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 352208/414113 [01:20<00:13, 4462.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 352655/414113 [01:20<00:13, 4452.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 353110/414113 [01:20<00:13, 4480.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 353569/414113 [01:20<00:13, 4510.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 354021/414113 [01:20<00:13, 4483.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 354470/414113 [01:20<00:13, 4467.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 354917/414113 [01:21<00:13, 4430.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 355369/414113 [01:21<00:13, 4455.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 355821/414113 [01:21<00:13, 4472.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 356283/414113 [01:21<00:12, 4514.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 356735/414113 [01:21<00:12, 4497.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 357185/414113 [01:21<00:12, 4434.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 357629/414113 [01:21<00:12, 4431.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 358073/414113 [01:21<00:12, 4417.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 358532/414113 [01:21<00:12, 4465.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 358996/414113 [01:22<00:12, 4513.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 359448/414113 [01:22<00:12, 4491.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 359899/414113 [01:22<00:12, 4495.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 360358/414113 [01:22<00:11, 4521.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 360811/414113 [01:22<00:11, 4466.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 361262/414113 [01:22<00:11, 4478.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 361711/414113 [01:22<00:12, 4351.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 362148/414113 [01:22<00:12, 4312.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 362589/414113 [01:22<00:11, 4338.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 363024/414113 [01:22<00:11, 4294.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 363454/414113 [01:23<00:11, 4288.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 363887/414113 [01:23<00:11, 4298.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 364329/414113 [01:23<00:11, 4332.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 364766/414113 [01:23<00:11, 4342.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 365212/414113 [01:23<00:11, 4375.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 365650/414113 [01:23<00:11, 4335.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 366087/414113 [01:23<00:11, 4341.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 366522/414113 [01:23<00:10, 4333.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 366969/414113 [01:23<00:10, 4373.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 367408/414113 [01:23<00:10, 4378.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 367846/414113 [01:24<00:10, 4363.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 368283/414113 [01:24<00:10, 4359.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 368739/414113 [01:24<00:10, 4418.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 369193/414113 [01:24<00:10, 4451.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 369639/414113 [01:24<00:10, 4430.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 370083/414113 [01:24<00:10, 4393.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 370523/414113 [01:24<00:10, 4348.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 370959/414113 [01:24<00:10, 4313.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 371391/414113 [01:24<00:09, 4314.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 371839/414113 [01:24<00:09, 4361.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 372276/414113 [01:25<00:09, 4346.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 372720/414113 [01:25<00:09, 4373.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 373167/414113 [01:25<00:09, 4401.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 373608/414113 [01:25<00:09, 4397.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 374055/414113 [01:25<00:09, 4418.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 374497/414113 [01:25<00:09, 4391.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 374955/414113 [01:25<00:08, 4445.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 375410/414113 [01:25<00:08, 4475.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 375858/414113 [01:25<00:08, 4442.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 376307/414113 [01:25<00:08, 4455.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 376753/414113 [01:26<00:08, 4424.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 377201/414113 [01:26<00:08, 4440.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 377650/414113 [01:26<00:08, 4454.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 378099/414113 [01:26<00:08, 4463.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 378546/414113 [01:26<00:07, 4446.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 378991/414113 [01:26<00:07, 4439.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 379436/414113 [01:26<00:07, 4406.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 379877/414113 [01:26<00:07, 4399.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 380318/414113 [01:26<00:07, 4379.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 380757/414113 [01:26<00:07, 4369.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 381212/414113 [01:27<00:07, 4419.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 381661/414113 [01:27<00:07, 4438.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 382111/414113 [01:27<00:07, 4454.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 382557/414113 [01:27<00:07, 4440.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 383016/414113 [01:27<00:06, 4481.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 383470/414113 [01:27<00:06, 4497.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 383920/414113 [01:27<00:06, 4483.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 384378/414113 [01:27<00:06, 4510.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 384830/414113 [01:27<00:06, 4397.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 385283/414113 [01:27<00:06, 4435.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 385728/414113 [01:28<00:06, 4416.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 386171/414113 [01:28<00:06, 4389.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 386611/414113 [01:28<00:06, 4375.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 387049/414113 [01:28<00:06, 4372.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 387499/414113 [01:28<00:06, 4408.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 387945/414113 [01:28<00:05, 4419.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 388388/414113 [01:28<00:05, 4396.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 388828/414113 [01:28<00:05, 4384.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 389278/414113 [01:28<00:05, 4418.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 389739/414113 [01:28<00:05, 4471.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 390187/414113 [01:29<00:05, 4463.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 390634/414113 [01:29<00:05, 4454.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 391080/414113 [01:29<00:05, 4433.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 391534/414113 [01:29<00:05, 4464.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 391981/414113 [01:29<00:04, 4439.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 392426/414113 [01:29<00:04, 4441.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 392872/414113 [01:29<00:04, 4444.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 393320/414113 [01:29<00:04, 4452.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 393773/414113 [01:29<00:04, 4474.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 394221/414113 [01:29<00:04, 4470.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 394680/414113 [01:30<00:04, 4505.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 395131/414113 [01:30<00:04, 4501.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 395582/414113 [01:30<00:04, 4448.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 396028/414113 [01:30<00:04, 4399.48it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 396482/414113 [01:30<00:03, 4439.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 396927/414113 [01:30<00:03, 4435.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 397371/414113 [01:30<00:03, 4341.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 397811/414113 [01:30<00:03, 4359.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 398248/414113 [01:30<00:03, 4352.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 398698/414113 [01:31<00:03, 4393.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 399138/414113 [01:31<00:03, 4368.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 399576/414113 [01:31<00:03, 4371.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 400023/414113 [01:31<00:03, 4400.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 400464/414113 [01:31<00:03, 4335.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 400898/414113 [01:31<00:03, 4332.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 401332/414113 [01:31<00:02, 4326.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 401769/414113 [01:31<00:02, 4337.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 402217/414113 [01:31<00:02, 4378.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 402659/414113 [01:31<00:02, 4389.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 403099/414113 [01:32<00:02, 4347.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 403536/414113 [01:32<00:02, 4354.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 403972/414113 [01:32<00:02, 4341.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 404422/414113 [01:32<00:02, 4387.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 404861/414113 [01:32<00:02, 4381.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 405300/414113 [01:32<00:02, 4271.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 405755/414113 [01:32<00:01, 4350.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 406191/414113 [01:32<00:01, 4306.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 406629/414113 [01:32<00:01, 4327.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 407067/414113 [01:32<00:01, 4342.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 407516/414113 [01:33<00:01, 4383.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 407955/414113 [01:33<00:01, 4358.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 408401/414113 [01:33<00:01, 4386.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 408864/414113 [01:33<00:01, 4456.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 409311/414113 [01:33<00:01, 4456.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 409770/414113 [01:33<00:00, 4494.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 410220/414113 [01:33<00:00, 4485.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 410669/414113 [01:33<00:00, 4471.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 411123/414113 [01:33<00:00, 4491.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 411579/414113 [01:33<00:00, 4509.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 412031/414113 [01:34<00:00, 4478.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 412482/414113 [01:34<00:00, 4484.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 412931/414113 [01:34<00:00, 4447.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 413390/414113 [01:34<00:00, 4488.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 413840/414113 [01:34<00:00, 4449.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 414113/414113 [01:34<00:00, 4381.69it/s]\u001b[A\u001b[ADownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "\n",
      "\n",
      "  0%|          | 0/102502400 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 1662976/102502400 [00:00<00:11, 9082764.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 7094272/102502400 [00:00<00:07, 12106535.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 14704640/102502400 [00:00<00:05, 16190340.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 21389312/102502400 [00:00<00:03, 20952027.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 26492928/102502400 [00:00<00:02, 25450893.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 34471936/102502400 [00:00<00:02, 31982464.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 42713088/102502400 [00:00<00:01, 39168071.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 50659328/102502400 [00:00<00:01, 45924376.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 58122240/102502400 [00:00<00:00, 51914711.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 65134592/102502400 [00:01<00:00, 39525963.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 72826880/102502400 [00:01<00:00, 44134877.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 79077376/102502400 [00:01<00:00, 48401059.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 86032384/102502400 [00:01<00:00, 53250818.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 92266496/102502400 [00:01<00:00, 54722800.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 98533376/102502400 [00:01<00:00, 56886193.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 102502400/102502400 [00:01<00:00, 55311585.85it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.90s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "import nltk\n",
    "nltk.download()\n",
    "# 'punkt'\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "# batch_size = 64          # first time\n",
    "batch_size = 200          #lets enjoy your gpu\n",
    "vocab_threshold = 6        #big enough size of vocab\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "# embed_size = 512           # dimensionality of image and word embeddings - as the paper suggested\n",
    "embed_size = 312  #so, at second try, after not seeing the improvment  iwould like to see, \n",
    "# i decided to decrease the number of embed size  maybe it was to large to get to generelize\n",
    "hidden_size = 250          # number of features in hidden state of the RNN decoder - decreased the hidden size\n",
    "num_epochs = 3             # number of training epochs - as you suggested\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 150          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params = params, lr = 0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first attemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/6471], Loss: 4.1382, Perplexity: 62.68868\n",
      "Epoch [1/3], Step [200/6471], Loss: 3.8981, Perplexity: 49.3076\n",
      "Epoch [1/3], Step [300/6471], Loss: 3.7886, Perplexity: 44.1958\n",
      "Epoch [1/3], Step [400/6471], Loss: 3.7034, Perplexity: 40.5859\n",
      "Epoch [1/3], Step [500/6471], Loss: 3.3545, Perplexity: 28.6310\n",
      "Epoch [1/3], Step [600/6471], Loss: 3.4793, Perplexity: 32.4380\n",
      "Epoch [1/3], Step [700/6471], Loss: 3.3007, Perplexity: 27.1310\n",
      "Epoch [1/3], Step [800/6471], Loss: 3.7158, Perplexity: 41.0905\n",
      "Epoch [1/3], Step [900/6471], Loss: 3.2597, Perplexity: 26.0414\n",
      "Epoch [1/3], Step [1000/6471], Loss: 2.9526, Perplexity: 19.1554\n",
      "Epoch [1/3], Step [1100/6471], Loss: 3.3603, Perplexity: 28.79773\n",
      "Epoch [1/3], Step [1200/6471], Loss: 3.2459, Perplexity: 25.6845\n",
      "Epoch [1/3], Step [1300/6471], Loss: 2.9287, Perplexity: 18.7028\n",
      "Epoch [1/3], Step [1400/6471], Loss: 3.7627, Perplexity: 43.0666\n",
      "Epoch [1/3], Step [1500/6471], Loss: 2.9206, Perplexity: 18.5532\n",
      "Epoch [1/3], Step [1600/6471], Loss: 2.9312, Perplexity: 18.7497\n",
      "Epoch [1/3], Step [1700/6471], Loss: 3.2354, Perplexity: 25.41567\n",
      "Epoch [1/3], Step [1800/6471], Loss: 3.0977, Perplexity: 22.1479\n",
      "Epoch [1/3], Step [1900/6471], Loss: 3.1592, Perplexity: 23.5513\n",
      "Epoch [1/3], Step [2000/6471], Loss: 3.4777, Perplexity: 32.3861\n",
      "Epoch [1/3], Step [2100/6471], Loss: 3.3841, Perplexity: 29.4928\n",
      "Epoch [1/3], Step [2200/6471], Loss: 3.1275, Perplexity: 22.8158\n",
      "Epoch [1/3], Step [2300/6471], Loss: 2.9814, Perplexity: 19.7163\n",
      "Epoch [1/3], Step [2400/6471], Loss: 3.1706, Perplexity: 23.8221\n",
      "Epoch [1/3], Step [2500/6471], Loss: 3.0897, Perplexity: 21.9702\n",
      "Epoch [1/3], Step [2600/6471], Loss: 3.0807, Perplexity: 21.7736\n",
      "Epoch [1/3], Step [2700/6471], Loss: 3.0118, Perplexity: 20.3244\n",
      "Epoch [1/3], Step [2800/6471], Loss: 3.2199, Perplexity: 25.0253\n",
      "Epoch [1/3], Step [2900/6471], Loss: 2.8442, Perplexity: 17.18846\n",
      "Epoch [1/3], Step [3000/6471], Loss: 2.9771, Perplexity: 19.6305\n",
      "Epoch [1/3], Step [3100/6471], Loss: 3.4644, Perplexity: 31.9566\n",
      "Epoch [1/3], Step [3200/6471], Loss: 2.9810, Perplexity: 19.7066\n",
      "Epoch [1/3], Step [3300/6471], Loss: 3.0272, Perplexity: 20.6399\n",
      "Epoch [1/3], Step [3400/6471], Loss: 3.1921, Perplexity: 24.3407\n",
      "Epoch [1/3], Step [3500/6471], Loss: 3.1819, Perplexity: 24.0935\n",
      "Epoch [1/3], Step [3600/6471], Loss: 2.9792, Perplexity: 19.6720\n",
      "Epoch [1/3], Step [3700/6471], Loss: 2.9957, Perplexity: 19.99888\n",
      "Epoch [1/3], Step [3800/6471], Loss: 3.1404, Perplexity: 23.1132\n",
      "Epoch [1/3], Step [3900/6471], Loss: 2.9721, Perplexity: 19.5334\n",
      "Epoch [1/3], Step [4000/6471], Loss: 2.9402, Perplexity: 18.9200\n",
      "Epoch [1/3], Step [4100/6471], Loss: 3.1797, Perplexity: 24.0384\n",
      "Epoch [1/3], Step [4200/6471], Loss: 3.0897, Perplexity: 21.9705\n",
      "Epoch [1/3], Step [4300/6471], Loss: 3.0856, Perplexity: 21.8814\n",
      "Epoch [1/3], Step [4400/6471], Loss: 2.9086, Perplexity: 18.3305\n",
      "Epoch [1/3], Step [4500/6471], Loss: 2.9671, Perplexity: 19.4363\n",
      "Epoch [1/3], Step [4600/6471], Loss: 2.7855, Perplexity: 16.2081\n",
      "Epoch [1/3], Step [4700/6471], Loss: 3.1823, Perplexity: 24.1010\n",
      "Epoch [1/3], Step [4800/6471], Loss: 2.9170, Perplexity: 18.48535\n",
      "Epoch [1/3], Step [4900/6471], Loss: 3.3066, Perplexity: 27.2910\n",
      "Epoch [1/3], Step [5000/6471], Loss: 2.9800, Perplexity: 19.6871\n",
      "Epoch [1/3], Step [5100/6471], Loss: 2.8816, Perplexity: 17.8421\n",
      "Epoch [1/3], Step [5200/6471], Loss: 2.9174, Perplexity: 18.4926\n",
      "Epoch [1/3], Step [5300/6471], Loss: 2.8861, Perplexity: 17.9232\n",
      "Epoch [1/3], Step [5400/6471], Loss: 2.9670, Perplexity: 19.4337\n",
      "Epoch [1/3], Step [5500/6471], Loss: 2.9065, Perplexity: 18.2931\n",
      "Epoch [1/3], Step [5600/6471], Loss: 2.6929, Perplexity: 14.7751\n",
      "Epoch [1/3], Step [5700/6471], Loss: 3.0131, Perplexity: 20.3504\n",
      "Epoch [1/3], Step [5800/6471], Loss: 2.7680, Perplexity: 15.9265\n",
      "Epoch [1/3], Step [5900/6471], Loss: 3.0705, Perplexity: 21.5523\n",
      "Epoch [1/3], Step [6000/6471], Loss: 2.9901, Perplexity: 19.8877\n",
      "Epoch [1/3], Step [6045/6471], Loss: 2.8781, Perplexity: 17.7798"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/6471], Loss: 4.1316, Perplexity: 62.27977\n",
      "Epoch [1/3], Step [200/6471], Loss: 4.0426, Perplexity: 56.97590\n",
      "Epoch [1/3], Step [300/6471], Loss: 3.9364, Perplexity: 51.2344\n",
      "Epoch [1/3], Step [400/6471], Loss: 3.5770, Perplexity: 35.7677\n",
      "Epoch [1/3], Step [500/6471], Loss: 3.5420, Perplexity: 34.5368\n",
      "Epoch [1/3], Step [600/6471], Loss: 3.2777, Perplexity: 26.5138\n",
      "Epoch [1/3], Step [700/6471], Loss: 3.2957, Perplexity: 26.9972\n",
      "Epoch [1/3], Step [800/6471], Loss: 3.4295, Perplexity: 30.8624\n",
      "Epoch [1/3], Step [900/6471], Loss: 3.0486, Perplexity: 21.0858\n",
      "Epoch [1/3], Step [1000/6471], Loss: 3.4956, Perplexity: 32.9691\n",
      "Epoch [1/3], Step [1100/6471], Loss: 3.3028, Perplexity: 27.18787\n",
      "Epoch [1/3], Step [1200/6471], Loss: 3.1524, Perplexity: 23.3926\n",
      "Epoch [1/3], Step [1300/6471], Loss: 3.2583, Perplexity: 26.0048\n",
      "Epoch [1/3], Step [1400/6471], Loss: 3.1377, Perplexity: 23.0510\n",
      "Epoch [1/3], Step [1500/6471], Loss: 3.5182, Perplexity: 33.7238\n",
      "Epoch [1/3], Step [1600/6471], Loss: 3.0368, Perplexity: 20.8385\n",
      "Epoch [1/3], Step [1700/6471], Loss: 3.2466, Perplexity: 25.7028\n",
      "Epoch [1/3], Step [1800/6471], Loss: 3.4168, Perplexity: 30.4722\n",
      "Epoch [1/3], Step [1900/6471], Loss: 3.2706, Perplexity: 26.3280\n",
      "Epoch [1/3], Step [2000/6471], Loss: 2.9457, Perplexity: 19.0233\n",
      "Epoch [1/3], Step [2100/6471], Loss: 3.0181, Perplexity: 20.45261\n",
      "Epoch [1/3], Step [2200/6471], Loss: 3.0067, Perplexity: 20.2206\n",
      "Epoch [1/3], Step [2300/6471], Loss: 3.1954, Perplexity: 24.4198\n",
      "Epoch [1/3], Step [2400/6471], Loss: 3.3461, Perplexity: 28.3927\n",
      "Epoch [1/3], Step [2500/6471], Loss: 3.1296, Perplexity: 22.8651\n",
      "Epoch [1/3], Step [2600/6471], Loss: 3.5317, Perplexity: 34.1804\n",
      "Epoch [1/3], Step [2700/6471], Loss: 3.1088, Perplexity: 22.3950\n",
      "Epoch [1/3], Step [2800/6471], Loss: 3.0932, Perplexity: 22.0486\n",
      "Epoch [1/3], Step [2900/6471], Loss: 3.1316, Perplexity: 22.9113\n",
      "Epoch [1/3], Step [3000/6471], Loss: 2.8621, Perplexity: 17.4979\n",
      "Epoch [1/3], Step [3100/6471], Loss: 3.0822, Perplexity: 21.8071\n",
      "Epoch [1/3], Step [3200/6471], Loss: 3.0113, Perplexity: 20.3147\n",
      "Epoch [1/3], Step [3300/6471], Loss: 3.2505, Perplexity: 25.8033\n",
      "Epoch [1/3], Step [3400/6471], Loss: 2.9791, Perplexity: 19.6702\n",
      "Epoch [1/3], Step [3500/6471], Loss: 2.9688, Perplexity: 19.4681\n",
      "Epoch [1/3], Step [3600/6471], Loss: 3.1016, Perplexity: 22.2343\n",
      "Epoch [1/3], Step [3700/6471], Loss: 2.9261, Perplexity: 18.6555\n",
      "Epoch [1/3], Step [3800/6471], Loss: 2.9773, Perplexity: 19.6341\n",
      "Epoch [1/3], Step [3900/6471], Loss: 2.9961, Perplexity: 20.0081\n",
      "Epoch [1/3], Step [4000/6471], Loss: 2.8761, Perplexity: 17.7445\n",
      "Epoch [1/3], Step [4100/6471], Loss: 3.1206, Perplexity: 22.6594\n",
      "Epoch [1/3], Step [4200/6471], Loss: 3.1549, Perplexity: 23.4512\n",
      "Epoch [1/3], Step [4300/6471], Loss: 2.9323, Perplexity: 18.7703\n",
      "Epoch [1/3], Step [4400/6471], Loss: 2.9094, Perplexity: 18.3462\n",
      "Epoch [1/3], Step [4500/6471], Loss: 3.2234, Perplexity: 25.1135\n",
      "Epoch [1/3], Step [4600/6471], Loss: 3.0742, Perplexity: 21.63167\n",
      "Epoch [1/3], Step [4700/6471], Loss: 3.0572, Perplexity: 21.2677\n",
      "Epoch [1/3], Step [4800/6471], Loss: 3.0016, Perplexity: 20.1185\n",
      "Epoch [1/3], Step [4900/6471], Loss: 3.0228, Perplexity: 20.5491\n",
      "Epoch [1/3], Step [5000/6471], Loss: 2.9562, Perplexity: 19.2252\n",
      "Epoch [1/3], Step [5100/6471], Loss: 3.2889, Perplexity: 26.8139\n",
      "Epoch [1/3], Step [5200/6471], Loss: 2.8573, Perplexity: 17.4137\n",
      "Epoch [1/3], Step [5300/6471], Loss: 2.9492, Perplexity: 19.0905\n",
      "Epoch [1/3], Step [5400/6471], Loss: 2.9258, Perplexity: 18.6494\n",
      "Epoch [1/3], Step [5500/6471], Loss: 3.5262, Perplexity: 33.9959\n",
      "Epoch [1/3], Step [5600/6471], Loss: 2.8194, Perplexity: 16.7663\n",
      "Epoch [1/3], Step [5700/6471], Loss: 2.9109, Perplexity: 18.3733\n",
      "Epoch [1/3], Step [5800/6471], Loss: 2.9661, Perplexity: 19.4159\n",
      "Epoch [1/3], Step [5900/6471], Loss: 2.9299, Perplexity: 18.7265\n",
      "Epoch [1/3], Step [6000/6471], Loss: 3.1079, Perplexity: 22.3736\n",
      "Epoch [1/3], Step [6100/6471], Loss: 2.8660, Perplexity: 17.5661\n",
      "Epoch [1/3], Step [6200/6471], Loss: 2.9498, Perplexity: 19.1026\n",
      "Epoch [1/3], Step [6300/6471], Loss: 2.9171, Perplexity: 18.4881\n",
      "Epoch [1/3], Step [6400/6471], Loss: 2.9076, Perplexity: 18.3130\n",
      "Epoch [2/3], Step [100/6471], Loss: 2.8714, Perplexity: 17.66194\n",
      "Epoch [2/3], Step [200/6471], Loss: 3.0282, Perplexity: 20.6603\n",
      "Epoch [2/3], Step [300/6471], Loss: 3.1058, Perplexity: 22.3270\n",
      "Epoch [2/3], Step [400/6471], Loss: 2.9307, Perplexity: 18.7406\n",
      "Epoch [2/3], Step [500/6471], Loss: 2.8146, Perplexity: 16.6859\n",
      "Epoch [2/3], Step [600/6471], Loss: 2.8660, Perplexity: 17.5672\n",
      "Epoch [2/3], Step [700/6471], Loss: 2.8124, Perplexity: 16.6497\n",
      "Epoch [2/3], Step [800/6471], Loss: 2.9260, Perplexity: 18.6537\n",
      "Epoch [2/3], Step [900/6471], Loss: 2.8813, Perplexity: 17.8379\n",
      "Epoch [2/3], Step [1000/6471], Loss: 2.8509, Perplexity: 17.3034\n",
      "Epoch [2/3], Step [1100/6471], Loss: 3.5399, Perplexity: 34.4648\n",
      "Epoch [2/3], Step [1200/6471], Loss: 2.8679, Perplexity: 17.5992\n",
      "Epoch [2/3], Step [1300/6471], Loss: 2.8637, Perplexity: 17.5267\n",
      "Epoch [2/3], Step [1400/6471], Loss: 2.7694, Perplexity: 15.9485\n",
      "Epoch [2/3], Step [1500/6471], Loss: 2.8533, Perplexity: 17.3455\n",
      "Epoch [2/3], Step [1600/6471], Loss: 3.0779, Perplexity: 21.7133\n",
      "Epoch [2/3], Step [1700/6471], Loss: 2.8789, Perplexity: 17.7942\n",
      "Epoch [2/3], Step [1800/6471], Loss: 2.8420, Perplexity: 17.1496\n",
      "Epoch [2/3], Step [1900/6471], Loss: 2.9662, Perplexity: 19.4175\n",
      "Epoch [2/3], Step [2000/6471], Loss: 2.9488, Perplexity: 19.0832\n",
      "Epoch [2/3], Step [2100/6471], Loss: 2.8786, Perplexity: 17.7891\n",
      "Epoch [2/3], Step [2200/6471], Loss: 2.8541, Perplexity: 17.3588\n",
      "Epoch [2/3], Step [2300/6471], Loss: 2.8107, Perplexity: 16.6221\n",
      "Epoch [2/3], Step [2400/6471], Loss: 2.7265, Perplexity: 15.2792\n",
      "Epoch [2/3], Step [2500/6471], Loss: 3.1102, Perplexity: 22.4249\n",
      "Epoch [2/3], Step [2600/6471], Loss: 3.0324, Perplexity: 20.7474\n",
      "Epoch [2/3], Step [2700/6471], Loss: 2.6145, Perplexity: 13.6605\n",
      "Epoch [2/3], Step [2800/6471], Loss: 2.8114, Perplexity: 16.6336\n",
      "Epoch [2/3], Step [2900/6471], Loss: 2.7121, Perplexity: 15.0605\n",
      "Epoch [2/3], Step [3000/6471], Loss: 2.7721, Perplexity: 15.9915\n",
      "Epoch [2/3], Step [3100/6471], Loss: 2.7455, Perplexity: 15.5720\n",
      "Epoch [2/3], Step [3200/6471], Loss: 2.8029, Perplexity: 16.4925\n",
      "Epoch [2/3], Step [3300/6471], Loss: 2.7567, Perplexity: 15.7476\n",
      "Epoch [2/3], Step [3400/6471], Loss: 2.7885, Perplexity: 16.2559\n",
      "Epoch [2/3], Step [3500/6471], Loss: 2.9409, Perplexity: 18.9336\n",
      "Epoch [2/3], Step [3600/6471], Loss: 2.9177, Perplexity: 18.4987\n",
      "Epoch [2/3], Step [3700/6471], Loss: 2.7290, Perplexity: 15.3174\n",
      "Epoch [2/3], Step [3800/6471], Loss: 2.7252, Perplexity: 15.2592\n",
      "Epoch [2/3], Step [3900/6471], Loss: 2.8367, Perplexity: 17.0598\n",
      "Epoch [2/3], Step [4000/6471], Loss: 2.8149, Perplexity: 16.6910\n",
      "Epoch [2/3], Step [4100/6471], Loss: 2.9751, Perplexity: 19.5924\n",
      "Epoch [2/3], Step [4200/6471], Loss: 2.7274, Perplexity: 15.2931\n",
      "Epoch [2/3], Step [4300/6471], Loss: 2.9446, Perplexity: 19.0028\n",
      "Epoch [2/3], Step [4400/6471], Loss: 3.7614, Perplexity: 43.0104\n",
      "Epoch [2/3], Step [4500/6471], Loss: 2.7731, Perplexity: 16.0084\n",
      "Epoch [2/3], Step [4600/6471], Loss: 2.8109, Perplexity: 16.6253\n",
      "Epoch [2/3], Step [4700/6471], Loss: 2.7582, Perplexity: 15.7717\n",
      "Epoch [2/3], Step [4800/6471], Loss: 2.9591, Perplexity: 19.2815\n",
      "Epoch [2/3], Step [4900/6471], Loss: 2.9505, Perplexity: 19.1163\n",
      "Epoch [2/3], Step [5000/6471], Loss: 2.8630, Perplexity: 17.5147\n",
      "Epoch [2/3], Step [5100/6471], Loss: 2.7001, Perplexity: 14.8811\n",
      "Epoch [2/3], Step [5200/6471], Loss: 3.0921, Perplexity: 22.0230\n",
      "Epoch [2/3], Step [5300/6471], Loss: 2.8052, Perplexity: 16.5304\n",
      "Epoch [2/3], Step [5400/6471], Loss: 2.8405, Perplexity: 17.1237\n",
      "Epoch [2/3], Step [5500/6471], Loss: 2.9847, Perplexity: 19.7802\n",
      "Epoch [2/3], Step [5600/6471], Loss: 2.8914, Perplexity: 18.0178\n",
      "Epoch [2/3], Step [5700/6471], Loss: 2.7756, Perplexity: 16.0480\n",
      "Epoch [2/3], Step [5800/6471], Loss: 2.9334, Perplexity: 18.7906\n",
      "Epoch [2/3], Step [5900/6471], Loss: 2.8677, Perplexity: 17.5966\n",
      "Epoch [2/3], Step [6000/6471], Loss: 2.7549, Perplexity: 15.7194\n",
      "Epoch [2/3], Step [6100/6471], Loss: 2.7585, Perplexity: 15.7763\n",
      "Epoch [2/3], Step [6200/6471], Loss: 3.1245, Perplexity: 22.7474\n",
      "Epoch [2/3], Step [6300/6471], Loss: 2.7137, Perplexity: 15.0846\n",
      "Epoch [2/3], Step [6400/6471], Loss: 2.9589, Perplexity: 19.2767\n",
      "Epoch [3/3], Step [100/6471], Loss: 2.8535, Perplexity: 17.34799\n",
      "Epoch [3/3], Step [200/6471], Loss: 2.8384, Perplexity: 17.0886\n",
      "Epoch [3/3], Step [300/6471], Loss: 2.8557, Perplexity: 17.3859\n",
      "Epoch [3/3], Step [400/6471], Loss: 2.8577, Perplexity: 17.4206\n",
      "Epoch [3/3], Step [500/6471], Loss: 2.6879, Perplexity: 14.7006\n",
      "Epoch [3/3], Step [600/6471], Loss: 3.1087, Perplexity: 22.3912\n",
      "Epoch [3/3], Step [700/6471], Loss: 2.7917, Perplexity: 16.3084\n",
      "Epoch [3/3], Step [800/6471], Loss: 3.0566, Perplexity: 21.2559\n",
      "Epoch [3/3], Step [900/6471], Loss: 2.8953, Perplexity: 18.0890\n",
      "Epoch [3/3], Step [1000/6471], Loss: 2.9829, Perplexity: 19.7450\n",
      "Epoch [3/3], Step [1100/6471], Loss: 2.7694, Perplexity: 15.9495\n",
      "Epoch [3/3], Step [1200/6471], Loss: 2.7423, Perplexity: 15.5230\n",
      "Epoch [3/3], Step [1300/6471], Loss: 2.9287, Perplexity: 18.70413\n",
      "Epoch [3/3], Step [1400/6471], Loss: 3.0271, Perplexity: 20.6381\n",
      "Epoch [3/3], Step [1500/6471], Loss: 2.9244, Perplexity: 18.6227\n",
      "Epoch [3/3], Step [1600/6471], Loss: 2.9594, Perplexity: 19.2855\n",
      "Epoch [3/3], Step [1700/6471], Loss: 2.8609, Perplexity: 17.4770\n",
      "Epoch [3/3], Step [1800/6471], Loss: 2.7382, Perplexity: 15.4584\n",
      "Epoch [3/3], Step [1900/6471], Loss: 2.8203, Perplexity: 16.7814\n",
      "Epoch [3/3], Step [2000/6471], Loss: 2.7331, Perplexity: 15.3807\n",
      "Epoch [3/3], Step [2100/6471], Loss: 2.8307, Perplexity: 16.9582\n",
      "Epoch [3/3], Step [2200/6471], Loss: 3.0051, Perplexity: 20.1881\n",
      "Epoch [3/3], Step [2300/6471], Loss: 2.9281, Perplexity: 18.6926\n",
      "Epoch [3/3], Step [2400/6471], Loss: 2.7523, Perplexity: 15.6782\n",
      "Epoch [3/3], Step [2500/6471], Loss: 2.7865, Perplexity: 16.2238\n",
      "Epoch [3/3], Step [2600/6471], Loss: 2.8823, Perplexity: 17.8552\n",
      "Epoch [3/3], Step [2700/6471], Loss: 2.9334, Perplexity: 18.7909\n",
      "Epoch [3/3], Step [2800/6471], Loss: 2.7358, Perplexity: 15.4217\n",
      "Epoch [3/3], Step [2900/6471], Loss: 2.7801, Perplexity: 16.1198\n",
      "Epoch [3/3], Step [3000/6471], Loss: 2.8868, Perplexity: 17.9360\n",
      "Epoch [3/3], Step [3100/6471], Loss: 2.8768, Perplexity: 17.7574\n",
      "Epoch [3/3], Step [3200/6471], Loss: 2.7450, Perplexity: 15.5651\n",
      "Epoch [3/3], Step [3300/6471], Loss: 2.8716, Perplexity: 17.6644\n",
      "Epoch [3/3], Step [3400/6471], Loss: 2.8717, Perplexity: 17.6670\n",
      "Epoch [3/3], Step [3500/6471], Loss: 2.9016, Perplexity: 18.2025\n",
      "Epoch [3/3], Step [3600/6471], Loss: 2.8901, Perplexity: 17.9954\n",
      "Epoch [3/3], Step [3700/6471], Loss: 2.7432, Perplexity: 15.5365\n",
      "Epoch [3/3], Step [3800/6471], Loss: 2.9782, Perplexity: 19.6525\n",
      "Epoch [3/3], Step [3900/6471], Loss: 2.8351, Perplexity: 17.0315\n",
      "Epoch [3/3], Step [4000/6471], Loss: 2.7126, Perplexity: 15.0684\n",
      "Epoch [3/3], Step [4100/6471], Loss: 2.9548, Perplexity: 19.1987\n",
      "Epoch [3/3], Step [4200/6471], Loss: 2.8572, Perplexity: 17.4135\n",
      "Epoch [3/3], Step [4300/6471], Loss: 2.6647, Perplexity: 14.3637\n",
      "Epoch [3/3], Step [4400/6471], Loss: 2.9415, Perplexity: 18.9442\n",
      "Epoch [3/3], Step [4500/6471], Loss: 2.9932, Perplexity: 19.9493\n",
      "Epoch [3/3], Step [4600/6471], Loss: 2.9301, Perplexity: 18.7291\n",
      "Epoch [3/3], Step [4700/6471], Loss: 2.9183, Perplexity: 18.5094\n",
      "Epoch [3/3], Step [4800/6471], Loss: 2.7186, Perplexity: 15.1597\n",
      "Epoch [3/3], Step [4900/6471], Loss: 3.0175, Perplexity: 20.4408\n",
      "Epoch [3/3], Step [5000/6471], Loss: 2.8615, Perplexity: 17.4871\n",
      "Epoch [3/3], Step [5100/6471], Loss: 3.0340, Perplexity: 20.7802\n",
      "Epoch [3/3], Step [5200/6471], Loss: 2.7758, Perplexity: 16.0519\n",
      "Epoch [3/3], Step [5300/6471], Loss: 2.7950, Perplexity: 16.3632\n",
      "Epoch [3/3], Step [5400/6471], Loss: 2.9176, Perplexity: 18.4970\n",
      "Epoch [3/3], Step [5500/6471], Loss: 2.6449, Perplexity: 14.0815\n",
      "Epoch [3/3], Step [5600/6471], Loss: 2.7409, Perplexity: 15.5015\n",
      "Epoch [3/3], Step [5700/6471], Loss: 2.7175, Perplexity: 15.1429\n",
      "Epoch [3/3], Step [5800/6471], Loss: 2.9179, Perplexity: 18.5022\n",
      "Epoch [3/3], Step [5900/6471], Loss: 2.9058, Perplexity: 18.2799\n",
      "Epoch [3/3], Step [6000/6471], Loss: 3.0676, Perplexity: 21.4904\n",
      "Epoch [3/3], Step [6100/6471], Loss: 2.7963, Perplexity: 16.3844\n",
      "Epoch [3/3], Step [6200/6471], Loss: 3.0619, Perplexity: 21.3671\n",
      "Epoch [3/3], Step [6300/6471], Loss: 3.1694, Perplexity: 23.7934\n",
      "Epoch [3/3], Step [6400/6471], Loss: 2.7557, Perplexity: 15.7326\n",
      "Epoch [3/3], Step [6471/6471], Loss: 2.7963, Perplexity: 16.3841"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [150/2071], Loss: 3.5488, Perplexity: 34.77138\n",
      "Epoch [1/3], Step [300/2071], Loss: 3.2509, Perplexity: 25.81245\n",
      "Epoch [1/3], Step [450/2071], Loss: 2.9892, Perplexity: 19.87020\n",
      "Epoch [1/3], Step [600/2071], Loss: 2.9478, Perplexity: 19.0642\n",
      "Epoch [1/3], Step [750/2071], Loss: 2.8102, Perplexity: 16.6125\n",
      "Epoch [1/3], Step [900/2071], Loss: 2.6452, Perplexity: 14.0868\n",
      "Epoch [1/3], Step [1050/2071], Loss: 3.9493, Perplexity: 51.9003\n",
      "Epoch [1/3], Step [1200/2071], Loss: 2.5503, Perplexity: 12.8112\n",
      "Epoch [1/3], Step [1350/2071], Loss: 2.4929, Perplexity: 12.0965\n",
      "Epoch [1/3], Step [1500/2071], Loss: 2.3700, Perplexity: 10.6969\n",
      "Epoch [1/3], Step [1650/2071], Loss: 2.4927, Perplexity: 12.0945\n",
      "Epoch [1/3], Step [1800/2071], Loss: 2.4492, Perplexity: 11.5796\n",
      "Epoch [1/3], Step [1950/2071], Loss: 2.4084, Perplexity: 11.1163\n",
      "Epoch [2/3], Step [150/2071], Loss: 2.7692, Perplexity: 15.94525\n",
      "Epoch [2/3], Step [300/2071], Loss: 2.3853, Perplexity: 10.8625\n",
      "Epoch [2/3], Step [450/2071], Loss: 2.3796, Perplexity: 10.8003\n",
      "Epoch [2/3], Step [600/2071], Loss: 2.2600, Perplexity: 9.58355\n",
      "Epoch [2/3], Step [750/2071], Loss: 2.2460, Perplexity: 9.44991\n",
      "Epoch [2/3], Step [900/2071], Loss: 2.2050, Perplexity: 9.07006\n",
      "Epoch [2/3], Step [1050/2071], Loss: 2.6743, Perplexity: 14.5028\n",
      "Epoch [2/3], Step [1200/2071], Loss: 2.7512, Perplexity: 15.6613\n",
      "Epoch [2/3], Step [1350/2071], Loss: 2.1935, Perplexity: 8.96615\n",
      "Epoch [2/3], Step [1500/2071], Loss: 2.2669, Perplexity: 9.64963\n",
      "Epoch [2/3], Step [1650/2071], Loss: 2.5471, Perplexity: 12.7697\n",
      "Epoch [2/3], Step [1800/2071], Loss: 2.8503, Perplexity: 17.2935\n",
      "Epoch [2/3], Step [1950/2071], Loss: 2.1241, Perplexity: 8.36534\n",
      "Epoch [3/3], Step [150/2071], Loss: 2.2806, Perplexity: 9.782209\n",
      "Epoch [3/3], Step [300/2071], Loss: 2.1807, Perplexity: 8.85230\n",
      "Epoch [3/3], Step [450/2071], Loss: 2.0720, Perplexity: 7.94082\n",
      "Epoch [3/3], Step [600/2071], Loss: 2.4977, Perplexity: 12.1547\n",
      "Epoch [3/3], Step [750/2071], Loss: 2.0739, Perplexity: 7.95558\n",
      "Epoch [3/3], Step [900/2071], Loss: 2.0602, Perplexity: 7.84749\n",
      "Epoch [3/3], Step [1050/2071], Loss: 2.1052, Perplexity: 8.20897\n",
      "Epoch [3/3], Step [1200/2071], Loss: 2.1195, Perplexity: 8.32698\n",
      "Epoch [3/3], Step [1350/2071], Loss: 2.4292, Perplexity: 11.3500\n",
      "Epoch [3/3], Step [1500/2071], Loss: 2.1907, Perplexity: 8.94180\n",
      "Epoch [3/3], Step [1650/2071], Loss: 2.0675, Perplexity: 7.90506\n",
      "Epoch [3/3], Step [1800/2071], Loss: 2.7538, Perplexity: 15.7028\n",
      "Epoch [3/3], Step [1950/2071], Loss: 2.2265, Perplexity: 9.26774\n",
      "Epoch [3/3], Step [2071/2071], Loss: 2.1989, Perplexity: 9.01478"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
